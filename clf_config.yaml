log_file: "./logs/clf/training_results.log"
roc_curves_plots_file: "./plots/clf/roc_curves/"
confusion_matrix_plots_file: "./plots/clf/confusion_matrix/"
models:
  decision_tree:
    criterion: "gini"
    splitter: "best"
    max_depth: null
    min_samples_split: 2
    random_state: 13


#https://www.kaggle.com/code/gorkemgunay/understanding-parameters-of-svm
  svm:
    kernel: "rbf"
    C: 1.0
    gamma: "scale"
    class_weight: null

  naive_bayes:
    model_type: "gaussian"  # Options: gaussian, multinomial, bernoulli



#https://www.kaggle.com/code/prashant111/random-forest-classifier-tutorial
  random_forest:
    n_estimators: 100
    min_samples_split: 2
    max_depth: null
    random_state: 13
    n_jobs: -1
    verbose: 0


# https://www.kaggle.com/code/prashant111/a-guide-on-xgboost-hyperparameters-tuning
  xgboost:
    n_estimators: 100
    max_depth: 6
    learning_rate: 0.1
    subsample: 0.8
    colsample_bytree: 0.8
    random_state: 13
    use_label_encoder: false
    eval_metric: "logloss"
    verbose: 0
  


  xgboost_grid_search_params:
    n_estimators: [50, 100]
    max_depth: [3, 4]
    learning_rate: [0.05, 0.1]
    subsample: [0.8]
    colsample_bytree: [0.8]
    gamma: [0]
    min_child_weight: [1, 3]
    reg_alpha: [0, 0.1]
    reg_lambda: [1, 2]
    num_class: [3]
    use_gpu: false
    objective: ["multi:softprob"]
    eval_metric: ["mlogloss"]


  knn:
    n_neighbors: 10
    metric: "manhattan"
